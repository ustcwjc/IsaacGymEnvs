import gym
import isaacgym
import isaacgymenvs
import torch
import numpy as np



from torch.distributions import Categorical
from isaacgym import gymapi

num_envs = 1


model_path = "runs/StrayTerrain_20-10-49-48/nn/StrayTerrain.pth"
loaded_dict = torch.load(model_path, map_location=torch.device('cuda:0'))

model = loaded_dict['model']
print("#########################",model.keys()) 
model.load_state_dict(loaded_dict['model'])
model.eval()

envs = isaacgymenvs.make(
	seed=42, 
	task="StrayTerrain", 
	num_envs=num_envs, 
	sim_device="cuda:0",
	rl_device="cuda:0",
	graphics_device_id=0,
)
print("Observation space is", envs.observation_space)
print("Action space is", envs.action_space)
envs.is_vector_env = True
# envs = gym.wrappers.RecordVideo(
# 	envs,
# 	"./videos",
# 	step_trigger=lambda step: step % 10000 == 0, # record the videos every 10000 steps
# 	video_length=100  # for each video record up to 100 steps
# )

obs=envs.reset()
print(obs['obs'])
observation = torch.tensor(obs['obs'], dtype=torch.float32).cuda()
actions = model(observation)
# model.eval()
# actions = model(obs)
# print(actions)

# for i in range(1000):
# 	actions = model.predict(obs)
    # obs, rewards, dones, info = envs.step(actions)
    # envs.step(actions)
# for _ in range(200):
# 	actions = model.predict(obs)
# 	obs, reward, dones, info = envs.step(actions)
# print(obs)
    